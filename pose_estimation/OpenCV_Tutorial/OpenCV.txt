This document is a light reading of the OpenCV documentation found online. The idea of this document
is to study and master the concept of OpenCV, one of the primary cruxes of the project coming up.


A) OpenCV, or open source computer vision library, is a library for processing of images and videos. it is written
in C/C++, making it fast and lightweight with proper binding to Python language. It processes images and videos by:
    1) read
    2) transforming
    3) detecting
    4) tracking
    5) recognizing
To unpack the process of processing images, we have to think about how computer vision works. In
its simplest form, images are percieved by digital devices as numerical values for each point in the image.
These are generally called pixels, which are represented as number values, and are generated and processed in 
matrices, or multidimensional arrays. Well, this module allows us to process and manipulate the numbers
stored within the matrices(eg. the pixels). 


B) Getting Started
Images: we can start with simple images, by reading displaying and writing it to a file. 
In order to read the photo, we can access it with cv2.imread() along with the existing image filename. 
We can protect the system protocol by putting a condition to exit if
the file is not found. Next, after reading the image, we display with cv2.imshow(). Finally, we
save the contents of the photo with cv2.imwrite() as a new image file. We can trigger a save
by mapping save with cv.waitKey(0)[to perform a process until a key is pressed] and ord('s'). ***NOTE: ord() reads the ASCii value of the letter
printed, which can help us prompt an action when pressing the computer key correspondent with the
ASCii letter. 

    import cv2 as cv
    import sys
 
    img = cv.imread(cv.samples.findFile("starry_night.jpg"))
 
    if img is None:
        sys.exit("Could not read the image.")
 
    cv.imshow("Display window", img)
    k = cv.waitKey(0)
 
    if k == ord("s"):
        cv.imwrite("starry_night.png", img)
B.1) 

C) Functions and builtins:
cv2.imread(path, flags) -> loads an image as a matrix object(in c++) or as a NumPy array(Python)
this loaded image can be read with imshow and imwrite.
cv2.imshow(window, image) -> Displays an image on a window

cv2.imwrite(path, image) -> saves an image. Image file is written as a matrix object 
with pixels as its contents, and is saved on the same path as the script is contained.

cv2.VideoCapture(index or path) -> Access to camera or video
>access must be made through a valid port with external resources or by use of 
of http and IP addresses with other software for videos. Otherwise, we can also
perform static image and video processing from jpg and mp4 files. Due to the limitations of chromebooks
and Crostini Virtual Hooks, we will be using the aid of DroidCam and other software tools
on the computer to access a camera for video processes.

> As an alternative, we can get a webcam for testing our first minimum product. Likewise
we can test with an iPhone using a USB to Lightning and using libimobiledevice tools to
talk to iPhones.

cv2.cvtColor(image, code) -> Convert color space

cv2.resize(image, dsize) -> Resizing

cv2.GaussianBlur(image, (k, k), sigma) -> Blurring of images, reduces high frequency detauls
(noise, sharp edges) by averaging pixel values with their neighbours.
To reduce these details, a matrix(known also as a kernel) is slid over an image and reduces
the pixels based on the kernel distribution. In the case of the GaussianBlur, the Gaussian distribution,
or bell curve, is taken into consideration. Edges are better preserved with Gaussian blurs than
on regular ones. 

cv2.Canny(image, threshold1, threshold2) -> edge detection

cv2.HoughCircles(...) -> detect circles

cv2.filter2D(source, default value, kernel) -> this makes edges and details more prominent.
> We create a custom kernel that emphasizes the difference between a pixel and its neighbor.
Negative weights subtract blurred surroundings, positive weights amplify the center pixel. 

cv2.CascadeClassifier(xml).detectMultiscale(img) -> detect faces/objects using Haar cascades

cv2.equalizeHist() -> this is used for the dilation and erosion of images, or the redistribution
of brightness values, thereby improving image contrast. Nromally. pixel intensities might cluster around a 
narrow range(for example, mostly dark pixels). Histpgram equialization stretcehs this distribution across the full
uint8(0-255) values. This makes bright areas brighter, dark areas darker, and makes clearer contrasts between
these spots.

C1) Trained models:
These trained models can be utilized with the CascadeClassifier()
Some of the more common ones include:

Haar Cascades:
    haarcascade_frontalface_default.xml
    haarcascade_frontalface_alt.xml
    haarcascade_frontalface_alt2.xml
    haarcascade_profileface.xml
    haarcascade_eye.xml
    haarcascade_eye_tree_eyeglasses.xml
    haarcascade_smile.xml
    haarcascade_fullbody.xml
    haarcascade_upperbody.xml
    haarcascade_lowerbody.xml

LBP Cascades (faster, less accurate):
    lbpcascade_frontalface.xml
    lbpcascade_profileface.xml
    lbpcascade_silverware.xml (yep, forks and spoons)

D) Though process for scripting with OpenCV:
it would be best to think in image-processing pipelines:
    1) Take an input. STart a process by capturing a new video with cv2.VideoCapture or by loading
an image to read with cv2.imread()

    2) Pre processing. we can process images or video captures. This is the time to think about the scope
of the image in question, and think about resizing, grayscale, noise reduction, etc. We can accomplish some of these with
cv2.GaussianBlur for altering blur of images and cv2.cvtColor to determine the colors to capture.

    3) Feature Extraction. this is the setting of aesthetics for the image or video captures, such a edges, corners
contours, faces, etc. We can get these done by use of the Canny, HoughCircles, findcontours, and CascadeClassifier
functions.

    4) Post processing. You can draw results, crop regions and combine with other logics, such as ML/MediaPipe
The functions that we can use here are cv2.rectangle, cv2.circle, cv2.putText

    5) Output. the final part of the process, generally involves to either display or save.
Done with cv2.imshow and cv2.imwrite


ðŸ”¹ Thought process for OpenCV scripts

Whenever you approach OpenCV, ask yourself:

Whatâ€™s my source? (camera, image, video file, generated frame)
What operation am I applying? (filter, detection, transformation, analysis)
Do I need to display or save results? (cv2.imshow for display, cv2.imwrite / cv2.VideoWriter for saving)

That structure makes your scripts modular.